# Netflix Subscriber Churn

This project applies a series of machine learning models to predict subscriber churn using a dataset modeled after Netflix's user base. In addition to model development, I perform feature engineering to identify the key factors that influence whether a subscriber is likely to churn. 

My interest in this topic stems from both personal experience, like many others, my Netflix usage surged during the COVID-19 pandemic, and the practical relevance of churn prediction in real-world subscription-model businesses. Companies such as Netflix likely rely on data-driven retention models, and this project represents a scaled-down version of how such analytics work in practice. 

This project focuses on the end-to-end machine learning workflow, including data cleaning and preparation, feature engineering, model development, evaluation, and interpretation. It also includes visualizations comparing predicted churn against actual churn using the test dataset (~20% of total records).

Key objectives of this project include:   
  - Determining which machine learning model is most appropriate for the churn-prediction task, balancing accuracy with model complexity and interpretability.  
  - Identifying the key factors that influence wheter a subscriber is likely to churn.  
  
This dataset is a publicly available on [Kaggle](https://www.kaggle.com/datasets/abdulwadood11220/netflix-customer-churn-dataset?resource=download&select=netflix_customer_churn.csv).  

## Dataset Description
The dataset contains over 5,000 synthetic customer records, representing subscriber behaviour for a video-streaming service modeled after Netflix. 

Key columns include: 
  - ``customer_id``
  - ``Churned``
*Additional features will be detailed in later sections.*

## Project Structure
*To be added once final project files are organized.*

## Objective 
The goal of this project is to develop a classification machine-learning model that predicts subscriber churn using historical customer behaviour data. To ensure the model is useful for decision-making, the focus will be on both interpretability and performance, guided by appropriate model evaluation metrics.  

## Approach
1. **Data Cleaning & Preprocessing:** Load, clean, and prepare the dataset by handling outliers, filling missing values, and removing duplicates.
2. **Exploratory Data Analysis (EDA):** Explore variable distributions, identify trends, and examine relationships and correlations through visualizations.  
3. **Feature Engineering:** Create new features from existing variables to improve model performance and extract deeper patterns. 
4. **Model Development:** Build, train, test, and tune multiple machine-learning models for comparison. 
5. **Model Evaluation & Interpretation:** Evaluate model accuracy and complexity, compare results across models, and interpret feature importance to understand drivers of churn. 

## Key Insights
*This section is currently in progress and will be updated shortly.*

<!---- Total sales volume and average home prices more than doubled over the 20-year period.-->
<!---- Real estate activity peaked during 2020-2022, a period largely influenced by the COVID-19 pandemic and low interest rates.-->  
<!---- Vancouver was the most popular city for real estate, with Downtown Vancouver & Downtown New Westminster ranking as the top neighbourhoods.-->     
<!---- Spring & Summer consisntely showed the highest sales activity within the year with clear seasonal peaks observed across multiple years-->  
<!--- Properties built after 2010 commanded a higher premium than older homes-->
<!--Key findings and visualizations will be summarized here once analysis is complete.-->

## Next Steps
*This section is currently in progress and will be updated shortly.*
